{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chainer_chemistry.datasets.numpy_tuple_dataset import NumpyTupleDataset\n",
    "from chainer_chemistry.datasets.molnet import get_molnet_dataset\n",
    "from chainer_chemistry.dataset.preprocessors.ggnn_preprocessor import GGNNPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chainer_chemistry.datasets.zinc import get_zinc250k\n",
    "#target_index = np.arange(500)  # For debug\n",
    "#dataset, smiles = get_zinc250k(preprocessor, labels='logP', target_index=target_index,\n",
    "#                       return_smiles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading delaney-processed.csv dataset, it takes time...\n",
      "Downloading from http://deepchem.io.s3-website-us-west-1.amazonaws.com/datasets/delaney-processed.csv...\n",
      "100%|██████████| 1128/1128 [00:00<00:00, 1201.78it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = GGNNPreprocessor()\n",
    "\n",
    "result = get_molnet_dataset('delaney', preprocessor, labels=None, return_smiles=True)\n",
    "train = result['dataset'][0]\n",
    "smiles = result['smiles'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer_chemistry.models.ggnn import GGNN\n",
    "from chainer.functions import relu, dropout\n",
    "\n",
    "from chainer_chemistry.models.mlp import MLP\n",
    "\n",
    "\n",
    "def activation_relu_dropout(h):\n",
    "    return dropout(relu(h), ratio=0.25)\n",
    "\n",
    "class GraphConvPredictor(chainer.Chain):\n",
    "    def __init__(self, graph_conv, mlp=None):\n",
    "        \"\"\"Initializes the graph convolution predictor.\n",
    "        Args:\n",
    "            graph_conv: The graph convolution network required to obtain\n",
    "                        molecule feature representation.\n",
    "            mlp: Multi layer perceptron; used as the final fully connected\n",
    "                 layer. Set it to `None` if no operation is necessary\n",
    "                 after the `graph_conv` calculation.\n",
    "        \"\"\"\n",
    "        super(GraphConvPredictor, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.graph_conv = graph_conv\n",
    "            if isinstance(mlp, chainer.Link):\n",
    "                self.mlp = mlp\n",
    "        if not isinstance(mlp, chainer.Link):\n",
    "            self.mlp = mlp\n",
    "\n",
    "    def __call__(self, atoms, adjs):\n",
    "        x = self.graph_conv(atoms, adjs)\n",
    "        if self.mlp:\n",
    "            x = self.mlp(x)\n",
    "        return x\n",
    "\n",
    "n_unit = 32\n",
    "conv_layers = 4\n",
    "class_num = 1\n",
    "\n",
    "ggnn = GGNN(out_dim=n_unit, hidden_dim=n_unit, n_layers=conv_layers)\n",
    "mlp = MLP(out_dim=class_num, hidden_dim=n_unit, activation=activation_relu_dropout)\n",
    "predictor = GraphConvPredictor(ggnn, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0  # -1 for CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer_chemistry.models.prediction.regressor import Regressor\n",
    "\n",
    "regressor = Regressor(predictor, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import iterators\n",
    "from chainer import optimizers\n",
    "from chainer import training\n",
    "from chainer.training import extensions as E\n",
    "\n",
    "from chainer_chemistry.dataset.converters import concat_mols\n",
    "\n",
    "\n",
    "def fit(model, dataset, batchsize=16, epoch=10, out='results/tmp', device=-1, converter=concat_mols):\n",
    "    train_iter = iterators.SerialIterator(train, batchsize)\n",
    "    optimizer = optimizers.Adam(alpha=0.0001)\n",
    "    optimizer.setup(model)\n",
    "\n",
    "    updater = training.StandardUpdater(\n",
    "        train_iter, optimizer, device=device, converter=converter)\n",
    "    trainer = training.Trainer(updater, (epoch, 'epoch'), out=out)\n",
    "\n",
    "    #trainer.extend(E.Evaluator(val_iter, classifier,\n",
    "    #                           device=device, converter=concat_mols))\n",
    "    trainer.extend(E.LogReport(), trigger=(1, 'epoch'))\n",
    "    trainer.extend(E.PrintReport([\n",
    "        'epoch', 'main/loss', 'main/accuracy', 'validation/main/loss',\n",
    "        'validation/main/accuracy', 'elapsed_time']))\n",
    "    trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   main/accuracy  validation/main/loss  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           2.48705                                                                    2.23334       \n",
      "\u001b[J2           2.76753                                                                    3.92877       \n",
      "\u001b[J3           1.77517                                                                    5.65369       \n",
      "\u001b[J4           1.59286                                                                    7.53278       \n",
      "\u001b[J5           2.94001                                                                    9.28092       \n",
      "\u001b[J6           2.06447                                                                    11.0126       \n",
      "\u001b[J7           1.15306                                                                    12.7165       \n",
      "\u001b[J8           1.72962                                                                    14.5397       \n",
      "\u001b[J9           2.26379                                                                    16.3012       \n",
      "\u001b[J10          2.75934                                                                    18.0012       \n",
      "\u001b[J11          1.54725                                                                    19.7434       \n",
      "\u001b[J12          2.29981                                                                    21.6597       \n",
      "\u001b[J13          2.61929                                                                    23.3601       \n",
      "\u001b[J14          2.36239                                                                    25.2215       \n",
      "\u001b[J15          1.12013                                                                    26.9714       \n",
      "\u001b[J16          3.76555                                                                    28.7189       \n",
      "\u001b[J17          0.924594                                                                   30.4458       \n",
      "\u001b[J18          1.07795                                                                    32.1407       \n",
      "\u001b[J19          0.824213                                                                   33.8693       \n",
      "\u001b[J20          1.08849                                                                    35.6437       \n",
      "\u001b[J21          1.16407                                                                    37.4669       \n",
      "\u001b[J22          1.18358                                                                    39.5211       \n",
      "\u001b[J23          1.01109                                                                    41.4241       \n",
      "\u001b[J24          1.50333                                                                    43.2098       \n",
      "\u001b[J25          1.89655                                                                    45.1997       \n",
      "\u001b[J26          1.01385                                                                    46.9054       \n",
      "\u001b[J27          1.08496                                                                    48.8352       \n",
      "\u001b[J28          1.39951                                                                    50.6467       \n",
      "\u001b[J29          0.567473                                                                   52.4011       \n",
      "\u001b[J30          1.0883                                                                     54.3419       \n",
      "\u001b[J31          0.725189                                                                   56.046        \n",
      "\u001b[J32          1.80318                                                                    57.7419       \n",
      "\u001b[J33          1.99419                                                                    59.5761       \n",
      "\u001b[J34          0.609655                                                                   61.3625       \n",
      "\u001b[J35          1.72831                                                                    63.095        \n",
      "\u001b[J36          0.868091                                                                   65.0246       \n",
      "\u001b[J37          1.51117                                                                    66.7909       \n",
      "\u001b[J38          0.668934                                                                   68.6401       \n",
      "\u001b[J39          1.36158                                                                    70.4274       \n",
      "\u001b[J40          1.41479                                                                    72.2528       \n"
     ]
    }
   ],
   "source": [
    "fit(regressor, train, batchsize=16, epoch=40, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer.functions as F\n",
    "\n",
    "from chainer_chemistry.saliency.calculator.gradient_calculator import GradientCalculator\n",
    "from chainer_chemistry.saliency.calculator.integrated_gradients_calculator import IntegratedGradientsCalculator\n",
    "from chainer_chemistry.link_hooks.variable_monitor_link_hook import VariableMonitorLinkHook\n",
    "\n",
    "\n",
    "\n",
    "def eval_fun(x, adj, t):\n",
    "    pred =  predictor(x, adj)\n",
    "    pred_summed = F.sum(pred)\n",
    "    return pred_summed\n",
    "\n",
    "# 1. instantiation\n",
    "#gradient_calculator = GradientCalculator(\n",
    "#    predictor, eval_fun=eval_fun, target_extractor=VariableMonitorLinkHook(ggnn.embed, timing='post'))\n",
    "calculator = IntegratedGradientsCalculator(\n",
    "    predictor, steps=5, eval_fun=eval_fun, target_extractor=VariableMonitorLinkHook(ggnn.embed, timing='post'),\n",
    "    device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.16s/it]\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.11s/it]\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from chainer_chemistry.saliency.calculator.common import GaussianNoiseSampler\n",
    "\n",
    "M = 5\n",
    "# 2. compute\n",
    "saliency_samples_vanilla = calculator.compute(\n",
    "    train, M=1, converter=concat_mols)\n",
    "saliency_samples_smooth = calculator.compute(\n",
    "    train, M=M, converter=concat_mols, noise_sampler=GaussianNoiseSampler())\n",
    "saliency_samples_bayes = calculator.compute(\n",
    "    train, M=M, converter=concat_mols, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer_chemistry.saliency.visualizer.mol_visualizer import SmilesVisualizer\n",
    "from chainer_chemistry.saliency.visualizer.common import abs_max_scaler\n",
    "\n",
    "\n",
    "visualizer = SmilesVisualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33a1147fa70402180fdab5fd2fa78f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=450, description='i', max=901), FloatSlider(value=0.5, description='ratio', max=1.0), Dropdown(description='method', options=('raw',), value='raw'), Dropdown(description='view', options=('view', 'save'), value='view'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.sv_visualize>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple plot demo\n",
    "import os\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def sv_visualize(i, ratio, method, view):\n",
    "    saliency_vanilla = calculator.aggregate(\n",
    "        saliency_samples_vanilla, ch_axis=3, method=method)\n",
    "    saliency_smooth = calculator.aggregate(\n",
    "        saliency_samples_smooth, ch_axis=3, method=method)\n",
    "    saliency_bayes = calculator.aggregate(\n",
    "        saliency_samples_bayes, ch_axis=3, method=method)\n",
    "    \n",
    "    scaler = abs_max_scaler\n",
    "    if view == 'view':\n",
    "        svg_vanilla = visualizer.visualize(saliency_vanilla[i], smiles[i], visualize_ratio=ratio, scaler=scaler)\n",
    "        svg_smooth = visualizer.visualize(saliency_smooth[i], smiles[i], visualize_ratio=ratio, scaler=scaler)\n",
    "        svg_bayes = visualizer.visualize(saliency_bayes[i], smiles[i], visualize_ratio=ratio, scaler=scaler)\n",
    "        display(svg_vanilla, svg_smooth, svg_bayes)\n",
    "        #display(svg_bayes)\n",
    "    elif view == 'save':\n",
    "        os.makedirs('results', exist_ok=True)\n",
    "        visualizer.visualize(saliency_vanilla[i], smiles[i], visualize_ratio=ratio, scaler=scaler,\n",
    "                     save_filepath='results/{}_vanilla.png'.format(i))\n",
    "        visualizer.visualize(saliency_smooth[i], smiles[i], visualize_ratio=ratio, scaler=scaler,\n",
    "                     save_filepath='results/{}_smooth.png'.format(i))\n",
    "        visualizer.visualize(saliency_bayes[i], smiles[i], visualize_ratio=ratio, scaler=scaler,\n",
    "                     save_filepath='results/{}_bayes.png'.format(i))\n",
    "        print('saved {}-th result!'.format(i))\n",
    "    else:\n",
    "        print(view, 'not supported')\n",
    "\n",
    "interact(sv_visualize, i=(0, len(train) - 1, 1), ratio=(0, 1.0, 0.1), method=['raw'], view=['view', 'save'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cairosvg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
